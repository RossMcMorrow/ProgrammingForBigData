{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://mrjob.readthedocs.io/en/latest/guides/writing-mrjobs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rc.py\n"
     ]
    }
   ],
   "source": [
    "%%file rc.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "DATA_RE = re.compile(r\"[\\w.-]+\")\n",
    "\n",
    "\n",
    "class MRProb2_3(MRJob):\n",
    "\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_sepW_setosa,\n",
    "                   reducer=self.reducer_get_avg)\n",
    "        ]\n",
    "\n",
    "    def mapper_get_sepW_setosa(self, _, line):\n",
    "        # yield each petal width\n",
    "        data = DATA_RE.findall(line)\n",
    "        if \"Iris-setosa\" in data:\n",
    "            sep_W = float(data[1])\n",
    "            yield (\"sepal width\", sep_W)\n",
    "\n",
    "    def reducer_get_avg(self, key, values):\n",
    "        # get max of the petal widths\n",
    "        size, total = 0, 0\n",
    "        for val in values:\n",
    "            size += 1\n",
    "            total += val\n",
    "        yield (\"setosa sepal width avg\", round(total,1) / size)\n",
    "if __name__ == '__main__':\n",
    "    MRProb2_3.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"setosa sepal width avg\"\t3.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\rossm\\AppData\\Local\\Temp\\rc.rossm.20210220.162843.353679\n",
      "Running step 1 of 1...\n",
      "job output is in C:\\Users\\rossm\\AppData\\Local\\Temp\\rc.rossm.20210220.162843.353679\\output\n",
      "Streaming final output from C:\\Users\\rossm\\AppData\\Local\\Temp\\rc.rossm.20210220.162843.353679\\output...\n",
      "Removing temp directory C:\\Users\\rossm\\AppData\\Local\\Temp\\rc.rossm.20210220.162843.353679...\n"
     ]
    }
   ],
   "source": [
    "!python rc.py iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mr_word_count.py\n"
     ]
    }
   ],
   "source": [
    "%%file mr_word_count.py \n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        yield \"chars\", len(line)\n",
    "        yield \"words\", len(line.split())\n",
    "        yield \"lines\", 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"chars\"\t191667\n",
      "\"lines\"\t4609\n",
      "\"words\"\t32105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_count.rossm.20210220.163703.408679\n",
      "Running step 1 of 1...\n",
      "job output is in C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_count.rossm.20210220.163703.408679\\output\n",
      "Streaming final output from C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_count.rossm.20210220.163703.408679\\output...\n",
      "Removing temp directory C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_count.rossm.20210220.163703.408679...\n"
     ]
    }
   ],
   "source": [
    "!python mr_word_count.py iris.data hamlet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mr_word_common.py\n"
     ]
    }
   ],
   "source": [
    "%%file mr_word_common.py \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,\n",
    "                   combiner=self.combiner_count_words,\n",
    "                   reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_find_max_word)\n",
    "        ]\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # yield each word in the line\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield (word.lower(), 1)\n",
    "\n",
    "    def combiner_count_words(self, word, counts):\n",
    "        # optimization: sum the words we've seen so far\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "    def reducer_count_words(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        yield None, (sum(counts), word)\n",
    "\n",
    "    # discard the key; it is just None\n",
    "    def reducer_find_max_word(self, _, word_count_pairs):\n",
    "        # each item of word_count_pairs is (count, word),\n",
    "        # so yielding one results in key=counts, value=word\n",
    "        yield max(word_count_pairs)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRMostUsedWord.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086\t\"the\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_common.rossm.20210220.164228.179195\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "job output is in C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_common.rossm.20210220.164228.179195\\output\n",
      "Streaming final output from C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_common.rossm.20210220.164228.179195\\output...\n",
      "Removing temp directory C:\\Users\\rossm\\AppData\\Local\\Temp\\mr_word_common.rossm.20210220.164228.179195...\n"
     ]
    }
   ],
   "source": [
    "!python mr_word_common.py iris.data hamlet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
